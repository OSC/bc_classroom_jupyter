
<%-
  container_sizes = {
    'small': {
      'cores': 1,
      'exec_mem': 1,
      'driver_mem': 1
    },
    'medium': {
      'cores': 2,
      'exec_mem': 2,
      'driver_mem': 2
    },
    'large': {
      'cores': 4,
      'exec_mem': 3,
      'driver_mem': 2
    },
    'extra-large': {
      'cores': 8,
      'exec_mem': 3,
      'driver_mem': 4
    },
  }
-%>

KERNEL_DIR="$JUPYTER_DATA_DIR/kernels/spark"
KERNEL_WRAPPER=$KERNEL_DIR/osc_kernel_wrapper.sh
KERNEL=$KERNEL_DIR/kernel.json

mkdir -p $KERNEL_DIR
touch $KERNEL_WRAPPER
chmod +x $KERNEL_WRAPPER
export KERNEL_WRAPPER

cp -r $PWD/assets/*.png $KERNEL_DIR
cp $PWD/kernel.json $KERNEL_DIR

cat > "${KERNEL_WRAPPER}" << HEREDOC
#!/bin/bash

module load spark/3.4.1

export SPARK_WORKER_CORES=<%= container_sizes[context.size.to_sym][:cores] %>

export PYTHONPATH="\${SPARK_HOME}/python:\$PYTHONPATH"
export PYTHONPATH="\${SPARK_PY4J_PATH}:\$PYTHONPATH"
export PYTHONSTARTUP="\${SPARK_HOME}/python/pyspark/shell.py"
export PYSPARK_SUBMIT_ARGS=" \\
    --driver-memory <%= container_sizes[context.size.to_sym][:driver_mem] %>G \\
    --executor-memory <%= container_sizes[context.size.to_sym][:exec_mem] %>G \\
    --conf spark.driver.maxResultSize=0 \\
    pyspark-shell"

exec python "\${@}"
HEREDOC

cat > "$KERNEL" << HEREDOC
{
  "argv": [
    "$KERNEL_WRAPPER",
    "-m",
    "ipykernel",
    "-f",
    "{connection_file}"
  ],
  "display_name": "PySpark"
}
HEREDOC
